{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f38a2711",
   "metadata": {},
   "source": [
    "# Meeting 2022-02-21\n",
    "\n",
    "This notebook describes how to extend JAX to include new primitives. Material was heavily based from this [source](https://jax.readthedocs.io/en/latest/notebooks/How_JAX_primitives_work.html) in the JAX Docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55b27b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import traceback\n",
    "import contextlib\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from jax import jit, grad, jvp, vjp, vmap, pmap, make_jaxpr, lax\n",
    "from jax.core import Primitive, ShapedArray\n",
    "from jax._src.lib import xla_client\n",
    "from jax.interpreters import xla, ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b768526",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDENT = 0\n",
    "SUPRESS = False\n",
    "\n",
    "def _trace(msg=None):\n",
    "    \"\"\"Prints a message at current indentation.\"\"\"\n",
    "    if msg is not None and not SUPRESS:\n",
    "        print(\"|   \" * INDENT + msg)\n",
    "\n",
    "\n",
    "def _trace_indent(msg=None):\n",
    "    \"\"\"Print a message and increase indentation.\"\"\"\n",
    "    global INDENT\n",
    "    _trace(msg)\n",
    "    INDENT = INDENT + 1\n",
    "\n",
    "\n",
    "def _trace_unindent(msg=None):\n",
    "    \"\"\"Decrease indentation and print a message.\"\"\"\n",
    "    global INDENT\n",
    "    INDENT = INDENT - 1\n",
    "    _trace(msg)\n",
    "\n",
    "\n",
    "def log_calls(name):\n",
    "    \"\"\"Decorator that shows when functions are invoked/returned.\"\"\"\n",
    "    def trace_func(fn):\n",
    "        def pp(v):\n",
    "            \"\"\"Pretty-print a value.\"\"\"\n",
    "            vtype = str(type(v))\n",
    "            if \"jax._src.lib.xla_bridge._JaxComputationBuilder\" in vtype:\n",
    "                return \"<JaxComputationBuilder>\"\n",
    "            if \"jaxlib.xla_extension.XlaOp\" in vtype:\n",
    "                return f\"<XlaOp at 0x{id(v):x}>\"\n",
    "            if (\"partial_eval.JaxprTracer\" in vtype or\n",
    "                \"batching.BatchTracer\" in vtype or\n",
    "                \"ad.JVPTracer\" in vtype):\n",
    "                return f\"Tracer<{v.aval}>\"\n",
    "            if isinstance(v, tuple):\n",
    "                return f\"({pp_vals(v)})\"\n",
    "\n",
    "            return str(v)\n",
    "\n",
    "        def pp_vals(args):\n",
    "            return \", \".join(pp(arg) for arg in args)\n",
    "\n",
    "        @functools.wraps(fn)\n",
    "        def fn_wrapper(*args):\n",
    "            \"\"\"Wrapper of fn that shows the calls as they happen.\"\"\"\n",
    "            _trace_indent(f\"| CALL {name}({pp_vals(args)})\")\n",
    "            res = fn(*args)\n",
    "            _trace_unindent(f\"| RET  {name} = {pp(res)}\")\n",
    "            return res\n",
    "\n",
    "        return fn_wrapper\n",
    "\n",
    "    return trace_func\n",
    "\n",
    "\n",
    "class ExpectNotImplemented:\n",
    "    def __enter__(self):\n",
    "        pass\n",
    "\n",
    "    def __exit__(self, typ, value, tb):\n",
    "        global INDENT\n",
    "        INDENT = 0\n",
    "        if typ is NotImplementedError:\n",
    "            print(f\"\\nFound expected exception:\")\n",
    "            traceback.print_exc(limit=3)\n",
    "            return True\n",
    "        elif typ is None:\n",
    "            assert False, \"Expected NotImplementedError\"\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def SuppressCallLog():\n",
    "    global SUPRESS\n",
    "    SUPRESS = True\n",
    "    try:\n",
    "        yield None\n",
    "    finally:\n",
    "        SUPRESS = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b01691",
   "metadata": {},
   "source": [
    "# PART 0: Last Week\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/flows.png\" width=\"80%\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba731049",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "## PART 1: JAX Primitives and JIT\n",
    "\n",
    "### Preparing the Ground\n",
    "\n",
    "Let us define a function that will be reimplemented as a primitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba7f0a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_calls(\"multiply_add_numpy\")\n",
    "def multiply_add_numpy(x, y, z):\n",
    "    return jnp.add(jnp.multiply(x, y), z)\n",
    "\n",
    "@log_calls(\"square_add_numpy\")\n",
    "def square_add_numpy(a, b):\n",
    "    return multiply_add_numpy(a, a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1882dd7e",
   "metadata": {},
   "source": [
    "**NORMAL EVALUATION**\n",
    "\n",
    "- Nested calls to `square_add_numpy` and `multiply_add_numpy`.\n",
    "- Floating point parameters.\n",
    "- Returns `DeviceArray` with expected value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "094373e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| CALL square_add_numpy(2.0, 10.0)\n",
      "|   | CALL multiply_add_numpy(2.0, 2.0, 10.0)\n",
      "|   | RET  multiply_add_numpy = 14.0\n",
      "| RET  square_add_numpy = 14.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(14., dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "square_add_numpy(2., 10.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06fe6eb",
   "metadata": {},
   "source": [
    "**GRADIENT EVALUATION**\n",
    "\n",
    "\n",
    "- Nested calls again.\n",
    "- Parameters are now `ConcreteArray`s. ðŸ¤”\n",
    "- Returns `DeviceArray` with the gradient evaluated at `(2., 10.)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3104f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| CALL square_add_numpy(Tracer<ConcreteArray(2.0, dtype=float32, weak_type=True)>, 10.0)\n",
      "|   | CALL multiply_add_numpy(Tracer<ConcreteArray(2.0, dtype=float32, weak_type=True)>, Tracer<ConcreteArray(2.0, dtype=float32, weak_type=True)>, 10.0)\n",
      "|   | RET  multiply_add_numpy = Tracer<ConcreteArray(14.0, dtype=float32, weak_type=True)>\n",
      "| RET  square_add_numpy = Tracer<ConcreteArray(14.0, dtype=float32, weak_type=True)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeviceArray(4., dtype=float32, weak_type=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad(square_add_numpy)(2., 10.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9968fa5",
   "metadata": {},
   "source": [
    "### Creating a new Primitive\n",
    "\n",
    "- Simply instantiate `Primitive` with a name.\n",
    "- The method `Primitive.bind` \"simply\" wraps the arguments in `Tracer`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a819dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiply_add_p = Primitive(\"multiply_add\")\n",
    "\n",
    "@log_calls(\"multiply_add_prim\")\n",
    "def multiply_add_prim(x, y, z):\n",
    "    \"\"\"The JAX-traceable way to use the JAX primitive\"\"\"\n",
    "    return multiply_add_p.bind(x, y, z)\n",
    "\n",
    "@log_calls(\"square_add_prim\")\n",
    "def square_add_prim(a, b):\n",
    "    \"\"\"The JAX-traceable way to use the JAX primitive\"\"\"\n",
    "    return multiply_add_p.bind(a, a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4e622c",
   "metadata": {},
   "source": [
    "We created a new primitive but did not tell JAX how it should be evaluated (i.e. which operations it should compute)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f656978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| CALL square_add_prim(2.0, 10.0)\n",
      "\n",
      "Found expected exception:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_13341/3035546393.py\", line 2, in <module>\n",
      "    square_add_prim(2., 10.)\n",
      "  File \"/tmp/ipykernel_13341/785201755.py\", line 50, in fn_wrapper\n",
      "    res = fn(*args)\n",
      "  File \"/tmp/ipykernel_13341/3651717411.py\", line 11, in square_add_prim\n",
      "    return multiply_add_p.bind(a, a, b)\n",
      "NotImplementedError: Evaluation rule for 'multiply_add' not implemented\n"
     ]
    }
   ],
   "source": [
    "with ExpectNotImplemented():\n",
    "    square_add_prim(2., 10.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477b1d87",
   "metadata": {},
   "source": [
    "Let us define an **concrete evaluation** implementation for our primitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abc5e5c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.multiply_add_impl(x, y, z)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@log_calls(\"multiply_add_impl\")\n",
    "def multiply_add_impl(x, y, z):\n",
    "  \"\"\"Concrete implementation of the primitive.\n",
    "\n",
    "  This function does NOT need to be JAX traceable.\n",
    "  \"\"\"\n",
    "  # Note that we can use the original numpy, which is not JAX traceable\n",
    "  return np.add(np.multiply(x, y), z)\n",
    "\n",
    "\n",
    "# Register the implementation of `multiply_add_p` primitive.\n",
    "multiply_add_p.def_impl(multiply_add_impl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0148bb2",
   "metadata": {},
   "source": [
    "Now we can call it.\n",
    "\n",
    "> **NOTE**: We are not doing JIT yet, this invocation is simply interpreting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5808171e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| CALL square_add_prim(2.0, 10.0)\n",
      "|   | CALL multiply_add_impl(2.0, 2.0, 10.0)\n",
      "|   | RET  multiply_add_impl = 14.0\n",
      "| RET  square_add_prim = 14.0\n"
     ]
    }
   ],
   "source": [
    "assert square_add_prim(2., 10.) == 14."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d68713b",
   "metadata": {},
   "source": [
    "### JIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf99901c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| CALL square_add_prim(Traced<ShapedArray(float32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>, Traced<ShapedArray(float32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>)\n",
      "\n",
      "Found expected exception:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_13341/1315100091.py\", line 2, in <module>\n",
      "    jit(square_add_prim)(2., 10.)\n",
      "  File \"/scratch/research/notebooks/venv/lib/python3.10/site-packages/jax/_src/traceback_util.py\", line 165, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "  File \"/scratch/research/notebooks/venv/lib/python3.10/site-packages/jax/_src/api.py\", line 430, in cache_miss\n",
      "    out_flat = xla.xla_call(\n",
      "NotImplementedError: Abstract evaluation for 'multiply_add' not implemented\n"
     ]
    }
   ],
   "source": [
    "with ExpectNotImplemented():\n",
    "    jit(square_add_prim)(2., 10.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f20b17b",
   "metadata": {},
   "source": [
    "Defining the **abstract evaluation** rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da24e7c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.multiply_add_abstract_eval(xs, ys, zs)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@log_calls(\"multiply_add_abstract_eval\")\n",
    "def multiply_add_abstract_eval(xs, ys, zs):\n",
    "    # Make sure paramters are compatible\n",
    "    assert xs.shape == ys.shape\n",
    "    assert xs.shape == zs.shape\n",
    "    # Inform that the output has the same shape as the inputs\n",
    "    return ShapedArray(xs.shape, xs.dtype)\n",
    "\n",
    "\n",
    "# Register the abstract implementation of `multiply_add_p` primitive.\n",
    "multiply_add_p.def_abstract_eval(multiply_add_abstract_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f83a39f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| CALL square_add_prim(Traced<ShapedArray(float32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>, Traced<ShapedArray(float32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>)\n",
      "|   | CALL multiply_add_abstract_eval(ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True))\n",
      "|   | RET  multiply_add_abstract_eval = ShapedArray(float32[])\n",
      "| RET  square_add_prim = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=0/1)>\n",
      "\n",
      "Found expected exception:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 191, in _run_module_as_main\n",
      "    msg = \"%s: %s\" % (sys.executable, exc)\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 75, in _run_code\n",
      "    fname = mod_spec.origin\n",
      "  File \"/scratch/research/notebooks/venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 12, in <module>\n",
      "    if sys.path[0] == '':\n",
      "jax._src.source_info_util.JaxStackTraceBeforeTransformation: NotImplementedError: MLIR translation rule for primitive 'multiply_add' not found for platform gpu\n",
      "\n",
      "The preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.\n",
      "\n",
      "--------------------\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_13341/1315100091.py\", line 2, in <module>\n",
      "    jit(square_add_prim)(2., 10.)\n",
      "  File \"/scratch/research/notebooks/venv/lib/python3.10/site-packages/jax/_src/traceback_util.py\", line 165, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "  File \"/scratch/research/notebooks/venv/lib/python3.10/site-packages/jax/_src/api.py\", line 430, in cache_miss\n",
      "    out_flat = xla.xla_call(\n",
      "NotImplementedError: MLIR translation rule for primitive 'multiply_add' not found for platform gpu\n"
     ]
    }
   ],
   "source": [
    "with ExpectNotImplemented():\n",
    "    jit(square_add_prim)(2., 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e37d52c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_calls(\"multiply_add_xla_translation\")\n",
    "def multiply_add_xla_translation(ctx, avals_in, avals_out, xc, yc, zc):\n",
    "    return [\n",
    "        xla_client.ops.Add(\n",
    "            xla_client.ops.Mul(xc, yc),\n",
    "            zc)\n",
    "    ]\n",
    "\n",
    "# Associate the new translation rule with our primitive\n",
    "xla.register_translation(multiply_add_p, multiply_add_xla_translation, platform='gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d3b1160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| CALL square_add_prim(Traced<ShapedArray(float32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>, Traced<ShapedArray(float32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>)\n",
      "|   | CALL multiply_add_abstract_eval(ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True))\n",
      "|   | RET  multiply_add_abstract_eval = ShapedArray(float32[])\n",
      "| RET  square_add_prim = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=0/1)>\n",
      "| CALL multiply_add_abstract_eval(ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True))\n",
      "| RET  multiply_add_abstract_eval = ShapedArray(float32[])\n",
      "| CALL multiply_add_xla_translation(TranslationContext(builder=<jaxlib.xla_extension.XlaBuilder object at 0x7f1cbc27e5b0>, platform='gpu', axis_env=AxisEnv(nreps=1, names=(), sizes=()), name_stack=''), [ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True)], [ShapedArray(float32[])], <XlaOp at 0x7f1c504ec9b0>, <XlaOp at 0x7f1c58c62e30>, <XlaOp at 0x7f1c54a63c30>)\n",
      "| RET  multiply_add_xla_translation = [<jaxlib.xla_extension.XlaOp object at 0x7f1c5045fc30>]\n"
     ]
    }
   ],
   "source": [
    "assert jit(square_add_prim)(2., 10.) == 14."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d41f1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| CALL square_add_prim(Traced<ShapedArray(float32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>, 10.0)\n",
      "|   | CALL multiply_add_abstract_eval(ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True))\n",
      "|   | RET  multiply_add_abstract_eval = ShapedArray(float32[])\n",
      "| RET  square_add_prim = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=0/1)>\n",
      "| CALL multiply_add_abstract_eval(ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True))\n",
      "| RET  multiply_add_abstract_eval = ShapedArray(float32[])\n",
      "| CALL multiply_add_xla_translation(TranslationContext(builder=<jaxlib.xla_extension.XlaBuilder object at 0x7f1c54a83c30>, platform='gpu', axis_env=AxisEnv(nreps=1, names=(), sizes=()), name_stack=''), [ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True), ShapedArray(float32[], weak_type=True)], [ShapedArray(float32[])], <XlaOp at 0x7f1c5046a3b0>, <XlaOp at 0x7f1c50469830>, <XlaOp at 0x7f1c7e1447f0>)\n",
      "| RET  multiply_add_xla_translation = [<jaxlib.xla_extension.XlaOp object at 0x7f1c50469b30>]\n"
     ]
    }
   ],
   "source": [
    "assert jit(lambda x, y: square_add_prim(x, y), static_argnums=1)(2., 10.) == 14."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3412f513",
   "metadata": {},
   "source": [
    "JAXPR/IR of the function that users regular `jax.numpy` (i.e. without our primitive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18a64ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ lambda ; a:f32[] b:f32[]. let c:f32[] = mul a a; d:f32[] = add c b in (d,) }\n",
      "================================================================================\n",
      "module @jit_square_add_numpy.11 {\n",
      "  func public @main(%arg0: tensor<f32>, %arg1: tensor<f32>) -> tensor<f32> {\n",
      "    %0 = mhlo.multiply %arg0, %arg0 : tensor<f32>\n",
      "    %1 = mhlo.add %0, %arg1 : tensor<f32>\n",
      "    return %1 : tensor<f32>\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with SuppressCallLog():\n",
    "    print(make_jaxpr(square_add_numpy)(2., 10.))\n",
    "    print(\"=\" * 80)\n",
    "    print(jit(square_add_numpy).lower(2., 10.).compiler_ir('mhlo'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ef5fe8",
   "metadata": {},
   "source": [
    "JAXPR/IR of the function that invokes our newly created primitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6020fe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ lambda ; a:f32[] b:f32[]. let c:f32[] = multiply_add a a b in (c,) }\n",
      "================================================================================\n",
      "module @jit_square_add_prim.12 {\n",
      "  func public @main(%arg0: tensor<f32>, %arg1: tensor<f32>) -> tensor<f32> {\n",
      "    %0 = call @multiply_add(%arg0, %arg0, %arg1) : (tensor<f32>, tensor<f32>, tensor<f32>) -> tensor<f32>\n",
      "    return %0 : tensor<f32>\n",
      "  }\n",
      "  func private @multiply_add(%arg0: tensor<f32>, %arg1: tensor<f32>, %arg2: tensor<f32>) -> tensor<f32> {\n",
      "    %0 = call @xla_fallback_multiply_add(%arg0, %arg1, %arg2) : (tensor<f32>, tensor<f32>, tensor<f32>) -> tensor<f32>\n",
      "    return %0 : tensor<f32>\n",
      "  }\n",
      "  func private @xla_fallback_multiply_add(%arg0: tensor<f32>, %arg1: tensor<f32>, %arg2: tensor<f32>) -> tensor<f32> {\n",
      "    %0 = mhlo.constant dense<false> : tensor<i1>\n",
      "    %1 = mhlo.multiply %arg0, %arg1 : tensor<f32>\n",
      "    %2 = mhlo.add %1, %arg2 : tensor<f32>\n",
      "    return %2 : tensor<f32>\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with SuppressCallLog():\n",
    "    print(make_jaxpr(square_add_prim)(2., 10.))\n",
    "    print(\"=\" * 80)\n",
    "    print(jit(square_add_prim).lower(2., 10.).compiler_ir('mhlo'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bf47dc",
   "metadata": {},
   "source": [
    "### RECAP:\n",
    "\n",
    "| Step | Description | API |\n",
    "|:----:|:------------|:----|\n",
    "| 1 | Create new primitive object | `Primitive(NAME)` |\n",
    "| 2 | Define concrete evaluation rule | `PRIMITIVE.def_impl(IMPL_FN)` |\n",
    "| 3 | Define abstract evaluation rule | `PRIMITIVE.def_abstract_eval(ABS_EVAL_FN)` |\n",
    "| 4 | Define translation rule | `xla.register_translation(PRIMITIVE, TRANSLATION_FN)` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583265b7",
   "metadata": {},
   "source": [
    "### JAX Core\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/jax_core.png\" alt=\"\" width=\"100%\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5339e9",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "## PART 2: JAX Primitives and Autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb31efb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| CALL square_add_prim(Tracer<ConcreteArray(2.0, dtype=float32, weak_type=True)>, Tracer<ConcreteArray(10.0, dtype=float32, weak_type=True)>)\n",
      "\n",
      "Found expected exception:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_13341/1685878697.py\", line 2, in <module>\n",
      "    jvp(square_add_prim, (2., 10.), (1., 1.))\n",
      "  File \"/scratch/research/notebooks/venv/lib/python3.10/site-packages/jax/_src/api.py\", line 2280, in jvp\n",
      "    return _jvp(lu.wrap_init(fun), primals, tangents, has_aux=has_aux)\n",
      "  File \"/scratch/research/notebooks/venv/lib/python3.10/site-packages/jax/_src/api.py\", line 2309, in _jvp\n",
      "    out_primals, out_tangents = ad.jvp(flat_fun).call_wrapped(ps_flat, ts_flat)\n",
      "NotImplementedError: Differentiation rule for 'multiply_add' not implemented\n"
     ]
    }
   ],
   "source": [
    "with ExpectNotImplemented():\n",
    "    jvp(square_add_prim, (2., 10.), (1., 1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139f1771",
   "metadata": {},
   "source": [
    "We have this function:\n",
    "\n",
    "$$ f(x, y, z) = x \\cdot y + z $$\n",
    "\n",
    "And we are computing its JVP as:\n",
    "\n",
    "$$ g(x, y, z) = x_t \\cdot y + (x \\cdot y_t + z_t) $$\n",
    "\n",
    "What is happening here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44ac01ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_calls(\"multiply_add_value_and_jvp\")\n",
    "def multiply_add_value_and_jvp(arg_values, arg_tangents):\n",
    "    \"\"\"Evaluates the primal output and the tangents (Jacobian-vector product).\n",
    "\n",
    "    Given values of the arguments and perturbation of the arguments (tangents), \n",
    "    compute the output of the primitive and the perturbation of the output.\n",
    "\n",
    "    This method must be JAX-traceable. JAX may invoke it with abstract values \n",
    "    for the arguments and tangents.\n",
    "    \"\"\"\n",
    "    x,  y,  z  = arg_values\n",
    "    xt, yt, zt = arg_tangents\n",
    "    \n",
    "    _trace(\">>> Primal evaluation:\")\n",
    "    primal_out = multiply_add_prim(x, y, z)\n",
    "    \n",
    "    def make_zero(tan):\n",
    "        return lax.zeros_like_array(x) if type(tan) is ad.Zero else tan\n",
    "    \n",
    "    _trace(\">>> Tangent evaluation:\")\n",
    "    output_tangent = multiply_add_prim(make_zero(xt), y, multiply_add_prim(x, make_zero(yt), make_zero(zt)))\n",
    "    \n",
    "    return primal_out, output_tangent\n",
    "\n",
    "# Register JVP rule for out `multiply_add_p` primitive\n",
    "ad.primitive_jvps[multiply_add_p] = multiply_add_value_and_jvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4eb3fbfb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| CALL square_add_prim(Tracer<ConcreteArray(2.0, dtype=float32, weak_type=True)>, Tracer<ConcreteArray(10.0, dtype=float32, weak_type=True)>)\n",
      "|   | CALL multiply_add_value_and_jvp((2.0, 2.0, 10.0), (1.0, 1.0, 1.0))\n",
      "|   |   >>> Primal evaluation:\n",
      "|   |   | CALL multiply_add_prim(2.0, 2.0, 10.0)\n",
      "|   |   |   | CALL multiply_add_impl(2.0, 2.0, 10.0)\n",
      "|   |   |   | RET  multiply_add_impl = 14.0\n",
      "|   |   | RET  multiply_add_prim = 14.0\n",
      "|   |   >>> Tangent evaluation:\n",
      "|   |   | CALL multiply_add_prim(2.0, 1.0, 1.0)\n",
      "|   |   |   | CALL multiply_add_impl(2.0, 1.0, 1.0)\n",
      "|   |   |   | RET  multiply_add_impl = 3.0\n",
      "|   |   | RET  multiply_add_prim = 3.0\n",
      "|   |   | CALL multiply_add_prim(1.0, 2.0, 3.0)\n",
      "|   |   |   | CALL multiply_add_impl(1.0, 2.0, 3.0)\n",
      "|   |   |   | RET  multiply_add_impl = 5.0\n",
      "|   |   | RET  multiply_add_prim = 5.0\n",
      "|   | RET  multiply_add_value_and_jvp = (14.0, 5.0)\n",
      "| RET  square_add_prim = Tracer<ConcreteArray(14.0, dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "assert jvp(square_add_prim, (2., 10.), (1., 1.)) == (14., 5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "516a3e99",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| CALL square_add_prim(Tracer<ConcreteArray(2.0, dtype=float32, weak_type=True)>, 10.0)\n",
      "|   | CALL multiply_add_value_and_jvp((Tracer<ConcreteArray(2.0, dtype=float32, weak_type=True)>, Tracer<ConcreteArray(2.0, dtype=float32, weak_type=True)>, 10.0), (Tracer<ShapedArray(float32[], weak_type=True)>, Tracer<ShapedArray(float32[], weak_type=True)>, Zero(ShapedArray(float32[], weak_type=True))))\n",
      "|   |   >>> Primal evaluation:\n",
      "|   |   | CALL multiply_add_prim(Tracer<ConcreteArray(2.0, dtype=float32, weak_type=True)>, Tracer<ConcreteArray(2.0, dtype=float32, weak_type=True)>, 10.0)\n",
      "|   |   |   | CALL multiply_add_impl(2.0, 2.0, 10.0)\n",
      "|   |   |   | RET  multiply_add_impl = 14.0\n",
      "|   |   | RET  multiply_add_prim = 14.0\n",
      "|   |   >>> Tangent evaluation:\n",
      "|   |   | CALL multiply_add_prim(Tracer<ConcreteArray(2.0, dtype=float32, weak_type=True)>, Tracer<ShapedArray(float32[], weak_type=True)>, 0.0)\n",
      "|   |   |   | CALL multiply_add_abstract_eval(ConcreteArray(2.0, dtype=float32, weak_type=True), ShapedArray(float32[], weak_type=True), ConcreteArray(0.0, dtype=float32, weak_type=True))\n",
      "|   |   |   | RET  multiply_add_abstract_eval = ShapedArray(float32[])\n",
      "|   |   | RET  multiply_add_prim = Tracer<ShapedArray(float32[])>\n",
      "|   |   | CALL multiply_add_prim(Tracer<ShapedArray(float32[], weak_type=True)>, Tracer<ConcreteArray(2.0, dtype=float32, weak_type=True)>, Tracer<ShapedArray(float32[])>)\n",
      "|   |   |   | CALL multiply_add_abstract_eval(ShapedArray(float32[], weak_type=True), ConcreteArray(2.0, dtype=float32, weak_type=True), ShapedArray(float32[]))\n",
      "|   |   |   | RET  multiply_add_abstract_eval = ShapedArray(float32[])\n",
      "|   |   | RET  multiply_add_prim = Tracer<ShapedArray(float32[])>\n",
      "|   | RET  multiply_add_value_and_jvp = (14.0, Tracer<ShapedArray(float32[])>)\n",
      "| RET  square_add_prim = Tracer<ConcreteArray(14.0, dtype=float32)>\n",
      "\n",
      "Found expected exception:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/scratch/research/notebooks/venv/lib/python3.10/site-packages/jax/interpreters/ad.py\", line 258, in get_primitive_transpose\n",
      "    return primitive_transposes[p]\n",
      "KeyError: multiply_add\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 191, in _run_module_as_main\n",
      "    msg = \"%s: %s\" % (sys.executable, exc)\n",
      "  File \"/usr/lib/python3.10/runpy.py\", line 75, in _run_code\n",
      "    fname = mod_spec.origin\n",
      "  File \"/scratch/research/notebooks/venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 12, in <module>\n",
      "    if sys.path[0] == '':\n",
      "jax._src.source_info_util.JaxStackTraceBeforeTransformation: NotImplementedError: Transpose rule (for reverse-mode differentiation) for 'multiply_add' not implemented\n",
      "\n",
      "The preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.\n",
      "\n",
      "--------------------\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_13341/4225762588.py\", line 2, in <module>\n",
      "    grad(square_add_prim)(2., 10.)\n",
      "  File \"/scratch/research/notebooks/venv/lib/python3.10/site-packages/jax/_src/traceback_util.py\", line 165, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "  File \"/scratch/research/notebooks/venv/lib/python3.10/site-packages/jax/_src/api.py\", line 994, in grad_f\n",
      "    _, g = value_and_grad_f(*args, **kwargs)\n",
      "NotImplementedError: Transpose rule (for reverse-mode differentiation) for 'multiply_add' not implemented\n"
     ]
    }
   ],
   "source": [
    "with ExpectNotImplemented():\n",
    "  grad(square_add_prim)(2., 10.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ed759ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_calls(\"multiply_add_transpose\")\n",
    "def multiply_add_transpose(ct, x, y, z):\n",
    "    \"\"\"Evaluates the transpose of a linear primitive.\n",
    "\n",
    "    This method is only used when computing the backward gradient following \n",
    "    value_and_jvp, and is only needed for primitives that are used in the JVP \n",
    "    calculation for some other primitive. We need transposition for multiply_add_prim, \n",
    "    because we have used multiply_add_prim in the computation of the output_tangent in \n",
    "    multiply_add_value_and_jvp.\n",
    "\n",
    "    In our case, multiply_add is not a linear primitive. However, it is used linearly \n",
    "    w.r.t. tangents in multiply_add_value_and_jvp:\n",
    "       output_tangent(xt, yt, zt) = multiply_add_prim(xt, y, multiply_add_prim(x, yt, zt))\n",
    "  \n",
    "    Always one of the first two multiplicative arguments is a constant.\n",
    "    \"\"\"\n",
    "    if not ad.is_undefined_primal(x):\n",
    "        # This use of multiply_add is with a constant \"x\"\n",
    "        assert ad.is_undefined_primal(y)\n",
    "        ct_y = ad.Zero(y.aval) if type(ct) is ad.Zero else multiply_add_prim(x, ct, lax.zeros_like_array(x))\n",
    "        return None, ct_y, ct\n",
    "    else:\n",
    "        # This use of multiply_add is with a constant \"y\"\n",
    "        assert ad.is_undefined_primal(x)\n",
    "        ct_x = ad.Zero(x.aval) if type(ct) is ad.Zero else multiply_add_prim(ct, y, lax.zeros_like_array(y))\n",
    "        return ct_x, None, ct\n",
    "        \n",
    "# Register transpose rule for `multiply_add_p` primitive.\n",
    "ad.primitive_transposes[multiply_add_p] = multiply_add_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b29efef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| CALL square_add_prim(Tracer<ConcreteArray(2.0, dtype=float32, weak_type=True)>, 10.0)\n",
      "|   | CALL multiply_add_value_and_jvp((Tracer<ConcreteArray(2.0, dtype=float32, weak_type=True)>, Tracer<ConcreteArray(2.0, dtype=float32, weak_type=True)>, 10.0), (Tracer<ShapedArray(float32[], weak_type=True)>, Tracer<ShapedArray(float32[], weak_type=True)>, Zero(ShapedArray(float32[], weak_type=True))))\n",
      "|   |   >>> Primal evaluation:\n",
      "|   |   | CALL multiply_add_prim(Tracer<ConcreteArray(2.0, dtype=float32, weak_type=True)>, Tracer<ConcreteArray(2.0, dtype=float32, weak_type=True)>, 10.0)\n",
      "|   |   |   | CALL multiply_add_impl(2.0, 2.0, 10.0)\n",
      "|   |   |   | RET  multiply_add_impl = 14.0\n",
      "|   |   | RET  multiply_add_prim = 14.0\n",
      "|   |   >>> Tangent evaluation:\n",
      "|   |   | CALL multiply_add_prim(Tracer<ConcreteArray(2.0, dtype=float32, weak_type=True)>, Tracer<ShapedArray(float32[], weak_type=True)>, 0.0)\n",
      "|   |   |   | CALL multiply_add_abstract_eval(ConcreteArray(2.0, dtype=float32, weak_type=True), ShapedArray(float32[], weak_type=True), ConcreteArray(0.0, dtype=float32, weak_type=True))\n",
      "|   |   |   | RET  multiply_add_abstract_eval = ShapedArray(float32[])\n",
      "|   |   | RET  multiply_add_prim = Tracer<ShapedArray(float32[])>\n",
      "|   |   | CALL multiply_add_prim(Tracer<ShapedArray(float32[], weak_type=True)>, Tracer<ConcreteArray(2.0, dtype=float32, weak_type=True)>, Tracer<ShapedArray(float32[])>)\n",
      "|   |   |   | CALL multiply_add_abstract_eval(ShapedArray(float32[], weak_type=True), ConcreteArray(2.0, dtype=float32, weak_type=True), ShapedArray(float32[]))\n",
      "|   |   |   | RET  multiply_add_abstract_eval = ShapedArray(float32[])\n",
      "|   |   | RET  multiply_add_prim = Tracer<ShapedArray(float32[])>\n",
      "|   | RET  multiply_add_value_and_jvp = (14.0, Tracer<ShapedArray(float32[])>)\n",
      "| RET  square_add_prim = Tracer<ConcreteArray(14.0, dtype=float32)>\n",
      "| CALL multiply_add_transpose(1.0, UndefinedPrimal(ShapedArray(float32[], weak_type=True)), 2.0, UndefinedPrimal(ShapedArray(float32[])))\n",
      "|   | CALL multiply_add_prim(1.0, 2.0, 0.0)\n",
      "|   |   | CALL multiply_add_impl(1.0, 2.0, 0.0)\n",
      "|   |   | RET  multiply_add_impl = 2.0\n",
      "|   | RET  multiply_add_prim = 2.0\n",
      "| RET  multiply_add_transpose = (2.0, None, 1.0)\n",
      "| CALL multiply_add_transpose(1.0, 2.0, UndefinedPrimal(ShapedArray(float32[], weak_type=True)), 0.0)\n",
      "|   | CALL multiply_add_prim(2.0, 1.0, 0.0)\n",
      "|   |   | CALL multiply_add_impl(2.0, 1.0, 0.0)\n",
      "|   |   | RET  multiply_add_impl = 2.0\n",
      "|   | RET  multiply_add_prim = 2.0\n",
      "| RET  multiply_add_transpose = (None, 2.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "assert grad(square_add_prim)(2., 10.) == 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec92850",
   "metadata": {},
   "source": [
    "### RECAP\n",
    "\n",
    "Consider a composition of functions $f(g(h(\\dots(z(x))))$. We normally evaluate such a function from inside-out, first calculate $z(x)$ then use the result as input to the next innermost function until we get to $f$. Similarly for evaluating functions, we decide to compute the derivative from inside-out or outside-in. These are known as forward mode autodiff and backward mode autodiff, respectively.\n",
    "\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/fwd_bwd_ad.png\", alt=\"autodiff\" width=\"30%\" />\n",
    "</center>\n",
    "\n",
    "- Is this correct or is it inverted?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990052a9",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "## PART 3: JAX Primitives and Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a633184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4457a03",
   "metadata": {},
   "source": [
    "### RECAP\n",
    "\n",
    "<center>\n",
    "    <img src=\"images/batching.png\" alt=\"batching\" width=\"50%\" />\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d509a6a",
   "metadata": {},
   "source": [
    "<hr />\n",
    "\n",
    "## PART 4: Summary\n",
    "\n",
    "1. Create a primitive:\n",
    "\n",
    "```python\n",
    "my_primitive_p = Primitive(\"my_primitive\")\n",
    "```\n",
    "\n",
    "2. Define a concrete evaluation rule for interpretation:\n",
    "\n",
    "```python\n",
    "my_primitive_p.def_impl(my_primitive_impl)\n",
    "```\n",
    "\n",
    "3. Define abstract evaluation rule for JIT compilation:\n",
    "\n",
    "```python\n",
    "my_primitive_p.def_abstract_eval(my_primitive_abs_eval)\n",
    "```\n",
    "\n",
    "4. Define XLA translation rule for JIT compilation:\n",
    "\n",
    "```python\n",
    "jax.interpreters.xla.register_translation(\n",
    "    my_primitive_p,\n",
    "    my_primitive_xla_compile_gpu,\n",
    "    platform='gpu')\n",
    "```\n",
    "\n",
    "5. Define Jacobian-Vector Product (JVP) rule for forward AD:\n",
    "\n",
    "```python\n",
    "jax.interpreters.ad.primitive_jvps[my_primitive_p] = my_primitive_value_and_jvp\n",
    "```\n",
    "\n",
    "6. Define transpose rule for backward AD:\n",
    "\n",
    "```python\n",
    "jax.interpreters.ad.primitive_transposes[my_primitive_p] = my_primitive_transpose\n",
    "```\n",
    "\n",
    "7. Define batching rule:\n",
    "\n",
    "```python\n",
    "jax.interpreters.batching.primitive_batchers[my_primitive_p] = my_primitive_batch\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
