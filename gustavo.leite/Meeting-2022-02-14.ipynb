{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a449c73",
   "metadata": {},
   "source": [
    "# Meeting 2022-02-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fe16fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from jax import (\n",
    "    # Transforms\n",
    "    jit,\n",
    "    grad,\n",
    "    pmap,\n",
    "    vmap,\n",
    "    make_jaxpr,\n",
    "    # Random numbers\n",
    "    random,\n",
    "    # Internals\n",
    "    xla_computation,\n",
    ")\n",
    "\n",
    "def hr():\n",
    "    \"\"\"Display a horizonal line.\"\"\"\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef095bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GpuDevice(id=0, process_index=0)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65146cba",
   "metadata": {},
   "source": [
    "## Intermediate Representations\n",
    "\n",
    "Some function:\n",
    "\n",
    "$$f(x) = x^2 + e^{-x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c9220d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = Traced<ShapedArray(float32[], weak_type=True)>with<DynamicJaxprTrace(level=0/1)>\n",
      "1.3678795\n",
      "--------------------------------------------------------------------------------\n",
      "1.3678795\n"
     ]
    }
   ],
   "source": [
    "@jit\n",
    "def f(x):\n",
    "    \"\"\"Simple square function.\"\"\"\n",
    "    print(f\"x = {x}\")\n",
    "    return x ** 2. + jnp.exp(-x)\n",
    "\n",
    "print(f(1.0))\n",
    "hr()\n",
    "print(f(1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dac0068",
   "metadata": {},
   "source": [
    "### JAXPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03d17748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ lambda ; a:f32[]. let\n",
       "    b:f32[] = xla_call[\n",
       "      call_jaxpr={ lambda ; c:f32[]. let\n",
       "          d:f32[] = pow c 2.0\n",
       "          e:f32[] = neg c\n",
       "          f:f32[] = exp e\n",
       "          g:f32[] = add d f\n",
       "        in (g,) }\n",
       "      name=f\n",
       "    ] a\n",
       "  in (b,) }"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_jaxpr(f)(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8d85c1",
   "metadata": {},
   "source": [
    "### HLO IR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2995b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<jaxlib.xla_extension.XlaComputation object at 0x7f5a2d5dd1b0>\n",
      "--------------------------------------------------------------------------------\n",
      "HloModule jit_f.0\n",
      "\n",
      "ENTRY main.7 {\n",
      "  Arg_0.1 = f32[] parameter(0)\n",
      "  constant.2 = f32[] constant(2)\n",
      "  power.3 = f32[] power(Arg_0.1, constant.2)\n",
      "  negate.4 = f32[] negate(Arg_0.1)\n",
      "  exponential.5 = f32[] exponential(negate.4)\n",
      "  ROOT add.6 = f32[] add(power.3, exponential.5)\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get HLO intermediate representation\n",
    "ir = f.lower(1.0).compiler_ir('hlo')\n",
    "\n",
    "print(repr(ir))\n",
    "hr()\n",
    "print(ir.as_hlo_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "712f6446",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<jaxlib.xla_extension.Executable object at 0x7f5a925a62b0>\n",
      "--------------------------------------------------------------------------------\n",
      "HloModule xla_computation_f.13\n",
      "\n",
      "%fused_computation (param_0.1: f32[]) -> f32[] {\n",
      "  %param_0.1 = f32[] parameter(0)\n",
      "  %multiply.1 = f32[] multiply(f32[] %param_0.1, f32[] %param_0.1), metadata={op_type=\"pow\" op_name=\"xla_computation(f)/jit(f)/pow\" source_file=\"/tmp/ipykernel_5746/3066188181.py\" source_line=4}\n",
      "  %negate.1 = f32[] negate(f32[] %param_0.1), metadata={op_type=\"neg\" op_name=\"xla_computation(f)/jit(f)/neg\" source_file=\"/tmp/ipykernel_5746/3066188181.py\" source_line=4}\n",
      "  %exponential.1 = f32[] exponential(f32[] %negate.1), metadata={op_type=\"exp\" op_name=\"xla_computation(f)/jit(f)/exp\" source_file=\"/tmp/ipykernel_5746/3066188181.py\" source_line=4}\n",
      "  ROOT %add.1 = f32[] add(f32[] %multiply.1, f32[] %exponential.1), metadata={op_type=\"add\" op_name=\"xla_computation(f)/jit(f)/add\" source_file=\"/tmp/ipykernel_5746/3066188181.py\" source_line=4}\n",
      "}\n",
      "\n",
      "ENTRY %xla_computation_f.13 (parameter.1: f32[]) -> (f32[]) {\n",
      "  %parameter.1 = f32[] parameter(0)\n",
      "  %fusion = f32[] fusion(f32[] %parameter.1), kind=kLoop, calls=%fused_computation, metadata={op_type=\"add\" op_name=\"xla_computation(f)/jit(f)/add\" source_file=\"/tmp/ipykernel_5746/3066188181.py\" source_line=4}\n",
      "  ROOT %tuple.12 = (f32[]) tuple(f32[] %fusion)\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import jax.lib.xla_bridge\n",
    "\n",
    "f_xla = xla_computation(f)(1.0)\n",
    "# Retrieve the XLA backend\n",
    "backend = jax.lib.xla_bridge.get_backend()\n",
    "# Compile and optimize function\n",
    "executable = backend.compile(f_xla)\n",
    "\n",
    "print(repr(executable))\n",
    "hr()\n",
    "print(executable.hlo_modules()[0].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43519ed",
   "metadata": {},
   "source": [
    "1. What is the difference between the two cells above?\n",
    "\n",
    "Relevant discussion [here](https://github.com/google/jax/discussions/7068)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14af0277",
   "metadata": {},
   "source": [
    "### MHLO - MLIR Dialect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c4fb959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<jaxlib.mlir._mlir_libs._mlir.ir.Module object at 0x7f5a2adbd8f0>\n",
      "--------------------------------------------------------------------------------\n",
      "module @jit_f.1 {\n",
      "  func public @main(%arg0: tensor<f32>) -> tensor<f32> {\n",
      "    %0 = mhlo.constant dense<2.000000e+00> : tensor<f32>\n",
      "    %1 = mhlo.power %arg0, %0 : tensor<f32>\n",
      "    %2 = \"mhlo.negate\"(%arg0) : (tensor<f32>) -> tensor<f32>\n",
      "    %3 = \"mhlo.exponential\"(%2) : (tensor<f32>) -> tensor<f32>\n",
      "    %4 = mhlo.add %1, %3 : tensor<f32>\n",
      "    return %4 : tensor<f32>\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get MHLO intermediate representation\n",
    "ir = f.lower(1.0).compiler_ir('mlho')\n",
    "\n",
    "print(repr(ir))\n",
    "hr()\n",
    "print(ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7836ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<jaxlib.mlir._mlir_libs._mlir.ir.Module object at 0x7f5a2adbc870>\n",
      "--------------------------------------------------------------------------------\n",
      "module @jit_f.2 {\n",
      "  func public @main(%arg0: tensor<3xf32>) -> tensor<3xf32> {\n",
      "    %0 = mhlo.constant dense<2.000000e+00> : tensor<f32>\n",
      "    %1 = \"mhlo.broadcast_in_dim\"(%0) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<3xf32>\n",
      "    %2 = mhlo.power %arg0, %1 : tensor<3xf32>\n",
      "    %3 = \"mhlo.negate\"(%arg0) : (tensor<3xf32>) -> tensor<3xf32>\n",
      "    %4 = \"mhlo.exponential\"(%3) : (tensor<3xf32>) -> tensor<3xf32>\n",
      "    %5 = mhlo.add %2, %4 : tensor<3xf32>\n",
      "    return %5 : tensor<3xf32>\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a vector of 1s\n",
    "v = jnp.array([1.0, 2.0, 3.0])\n",
    "# Get MHLO intermediate representation\n",
    "ir = f.lower(v).compiler_ir()\n",
    "\n",
    "print(repr(ir))\n",
    "hr()\n",
    "print(ir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bdd17d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<jaxlib.mlir._mlir_libs._mlir.ir.Module object at 0x7f5a2adf96f0>\n",
      "--------------------------------------------------------------------------------\n",
      "module @jit_f.8 {\n",
      "  func public @main(%arg0: tensor<2x2xf32>) -> tensor<2x2xf32> {\n",
      "    %0 = mhlo.constant dense<2.000000e+00> : tensor<f32>\n",
      "    %1 = \"mhlo.broadcast_in_dim\"(%0) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>) -> tensor<2x2xf32>\n",
      "    %2 = mhlo.power %arg0, %1 : tensor<2x2xf32>\n",
      "    %3 = \"mhlo.negate\"(%arg0) : (tensor<2x2xf32>) -> tensor<2x2xf32>\n",
      "    %4 = \"mhlo.exponential\"(%3) : (tensor<2x2xf32>) -> tensor<2x2xf32>\n",
      "    %5 = mhlo.add %2, %4 : tensor<2x2xf32>\n",
      "    return %5 : tensor<2x2xf32>\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a 2x2 identity matrix\n",
    "I = jnp.eye(2)\n",
    "# Get MHLO intermediate representation\n",
    "ir = f.lower(I).compiler_ir()\n",
    "\n",
    "print(repr(ir))\n",
    "hr()\n",
    "print(ir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7198a8e",
   "metadata": {},
   "source": [
    "## PMAP attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00d79030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling computation that requires 10 logical devices, but only 1 XLA devices are available (num_replicas=10, num_partitions=1)\n"
     ]
    }
   ],
   "source": [
    "from jax import random\n",
    "\n",
    "# Generate input arrays\n",
    "key = random.PRNGKey(0)\n",
    "A = jnp.ones(10)\n",
    "B = jnp.ones(10)\n",
    "\n",
    "try:\n",
    "    # PMAP dot product operation\n",
    "    dot_pmap = pmap(jnp.dot)(A, B)\n",
    "except ValueError as error:\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88419c1",
   "metadata": {},
   "source": [
    "## MPI4JAX & JAX Primitives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddbed78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ lambda ; a:f32[]. let\n",
       "    b:f32[] = xla_call[\n",
       "      call_jaxpr={ lambda ; c:f32[]. let\n",
       "          d:f32[] = add c 0.0\n",
       "          e:Tok = create_token \n",
       "          f:f32[] _:Tok = allreduce_mpi[\n",
       "            comm=<mpi4jax._src.utils.HashableMPIType object at 0x7f5a1876c280>\n",
       "            op=<mpi4jax._src.utils.HashableMPIType object at 0x7f5a1876c130>\n",
       "            transpose=False\n",
       "          ] d e\n",
       "        in (f,) }\n",
       "      name=foo\n",
       "    ] a\n",
       "  in (b,) }"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mpi4jax\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "@jax.jit\n",
    "def foo(arr):\n",
    "   arr = arr + rank\n",
    "   arr_sum, _ = mpi4jax.allreduce(arr, op=MPI.SUM, comm=comm)\n",
    "   return arr_sum\n",
    "\n",
    "make_jaxpr(foo)(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9936d35",
   "metadata": {},
   "source": [
    "## STAX, FLAX, TRAX\n",
    "\n",
    "- [STAX][1]: Experimental NN library inside JAX repo.\n",
    "- [FLAX][2]: NN library with functional style based on JAX by Google Brain team. (2.6k stars)\n",
    "- [TRAX][3]: Fully-featured NN library based on JAX by Google Brain team. (6.8k stars)\n",
    "\n",
    "[1]: https://github.com/google/jax/tree/main/jax/example_libraries\n",
    "[2]: https://github.com/google/flax\n",
    "[3]: https://github.com/google/trax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7ebb57",
   "metadata": {},
   "source": [
    "## 1D Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e9a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.PRNGKey(0)\n",
    "array = jnp.ones((10,))\n",
    "mask = jnp.array([1.0, 2.0, 1.0])\n",
    "\n",
    "jnp.convolve(array, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd06a4e",
   "metadata": {},
   "source": [
    "## Plans\n",
    "\n",
    "- [ ] Continue studying JAX implementation\n",
    "- [ ] Study basics of XLA/HLO\n",
    "- [ ] Write minimal example using PMAP/PJIT @ local/cluster\n",
    "- [ ] Write minimal example using PMAP/PJIT @ Google Collab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
